{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Basics of Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this module we are going to learn about neural networks in scikit-learn. While scikit-learn is not the most used library for neural networks and deep learning, there is some built-in functionality in scikit-learn that can be used. We are going to focus on how neural networks conceptually work, and demonstrate basic usage of the scikit-learn implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Functions and attributes in this lecture: </b>\n",
    "- `sklearn.neural_network` - Submodule for neural networks\n",
    " - `MLPClassifier` - The Multi-Layer Perceptron implementation for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _covtype_dataset:\n",
      "\n",
      "Forest covertypes\n",
      "-----------------\n",
      "\n",
      "The samples in this dataset correspond to 30Ã—30m patches of forest in the US,\n",
      "collected for the task of predicting each patch's cover type,\n",
      "i.e. the dominant species of tree.\n",
      "There are seven covertypes, making this a multiclass classification problem.\n",
      "Each sample has 54 features, described on the\n",
      "`dataset's homepage <https://archive.ics.uci.edu/ml/datasets/Covertype>`__.\n",
      "Some of the features are boolean indicators,\n",
      "while others are discrete or continuous measurements.\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    =================   ============\n",
      "    Classes                        7\n",
      "    Samples total             581012\n",
      "    Dimensionality                54\n",
      "    Features                     int\n",
      "    =================   ============\n",
      "\n",
      ":func:`sklearn.datasets.fetch_covtype` will load the covertype dataset;\n",
      "it returns a dictionary-like 'Bunch' object\n",
      "with the feature matrix in the ``data`` member\n",
      "and the target values in ``target``. If optional argument 'as_frame' is\n",
      "set to 'True', it will return ``data`` and ``target`` as pandas\n",
      "data frame, and there will be an additional member ``frame`` as well.\n",
      "The dataset will be downloaded from the web if necessary.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Non-sklearn packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Sklearn packages\n",
    "from sklearn.datasets import fetch_covtype\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "\n",
    "# Importing the dataset\n",
    "X, y = fetch_covtype(return_X_y=True, as_frame=True)\n",
    "\n",
    "# Printing the description for the dataset\n",
    "print(fetch_covtype()[\"DESCR\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Usage of the MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us first see how the MLPClassifier works. It has a very familiar interface, and should thus not be difficult to get started with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training set and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the MLPClassifier\n",
    "mlp_classifier = MLPClassifier(hidden_layer_sizes=(5,), activation='relu', random_state=42, max_iter=300).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.36299292, 0.48981176, 0.06108747, 0.00470559, 0.01609391,\n",
       "        0.02990747, 0.03540088]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Can predict probabilities of a new observation\n",
    "mlp_classifier.predict_proba(X_test[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Can predict by choosing the probability with the highest score\n",
    "mlp_classifier.predict(X_test[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48777472957326296"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean accuracy of the model\n",
    "mlp_classifier.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking out some of the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choosing other hidden layer values\n",
    "mlp_classifier_two_hidden_layers = MLPClassifier(hidden_layer_sizes=(13, 6), activation='relu', random_state=42, max_iter=300).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7278260506743718"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking out the accuracy again\n",
    "mlp_classifier_two_hidden_layers.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can basically treat the MLPClassifier like any other estimator in scikit-learn. Doing hyperparameter-search over the parameter `hidden_layer_sizes` is very expensive time-wise. There is a lot of speed improvements that GPUs can give to neural networks, but this is not available in the scikit-learn implementation. I suggest the library `Keras` if you are interested in learning more about neural networks. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
